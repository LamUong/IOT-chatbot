{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 332470 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "embeddings_index = {}\n",
    "GLOVE_DIR = 'data'\n",
    "additional_texts=\" \"\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.300d.txt'))\n",
    "for i, line in enumerate(f):\n",
    "    values = line.split(' ')\n",
    "    word = values[0]\n",
    "    word = porter_stemmer.stem(word)\n",
    "    additional_texts+=word+\" \"\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pickle\n",
    "L = [\n",
    "{\n",
    "\"patterns\": [\"Hi there bot, What is CTC?\", \"Tell me more about CTC.\", \"Please explain what is Connected Traffic Cloud\", \n",
    "\"Is there any information on CTC\", \"Give me some details about Connected Traffic Cloud\",\n",
    "             \"test Hey bot what is Connected Traffic Cloud?\",\n",
    "             \"test Tell me about CTC?\",\n",
    "\"Hey bot, What is behind CTC?\", \n",
    "             \"What technologies powered CTC\", \n",
    "\"Which team in Ericsson is behind Connected Traffic Cloud?\", \n",
    "\"What is IOT accelerator\", \"How is IOT platform related to CTC\",\"How is IOT platform related to  Connected Traffic Cloud\",\n",
    "             \"test Hey bot what is behind Connected Urban Transport?\",\n",
    "             \"test How is this CTC technology powered by Ericsson?\"],\n",
    " \n",
    "\"responses\": [ \"CTC stands for Connected Traffic Cloud. \\\n",
    " Cities have existing traffic related applications and devices, often disjoint and built in silos from decades ago. \\\n",
    " As cities become smarter, there is a need for a system of systems to connect and cooperate with existing and future infrastructure, \\\n",
    " and provide a single interface for overview and control of city infrastructure.\\\n",
    " CTC is Ericsson's answer to address the Connected Urban Transport.\\\n",
    " CTC has 3 main purposes. 1. It is an industrial IoT platform that handles device and data management. \\\n",
    " 2. It is an overlay system that integrates with partners with a system of system approach. \\\n",
    " 3. It offers hosting of partner and Ericsson software applications\\\n",
    " Ericsson Connected Urban Transport is a unique service offering that connects both Infrastructure assets - \\\n",
    "such as Traffic Lights, Cameras, Variable Signs - as well as vehicles, bus fleets and people.\"],\n",
    "\n",
    "\"intent\": [\"General_Information\",\"CTC\"]\n",
    "},\n",
    "    \n",
    "{\n",
    "\"patterns\": [\"Hey bot, What is CUT?\", \"Tell me more about CUT.\", \"Please explain what is Connected Urban Transport\", \n",
    "\"I would like to know more about Connected Urban Transport\", \n",
    "\"Is there any information on CUT\", \n",
    "\"would it be possible for you to explain to me what is CUT\",\"test Hey bot what is Connected Urban Transport?\",\"test Tell me about CUT?\"],\n",
    "\n",
    "\"responses\": [ \"Ericsson Connected Urban Transport is a unique service offering that connects both Infrastructure assets - \\\n",
    "such as Traffic Lights, Cameras, Variable Signs - as well as vehicles, bus fleets and people. \"],\n",
    "\n",
    "\"intent\": [\"General_Information\",\"CUT\"]\n",
    "},\n",
    "    \n",
    "{\n",
    "\"patterns\": [\"Ok, I'm interested to know more, can I see a demo?\",\n",
    "             \"Is there any demo on CUT\", \n",
    "             \"Open a demo of Connected Urban Transport\", \n",
    "\"would it be possible for you to show  me what a demo of CUT\",\n",
    "             \"test Hey bot is there any demo?\",\n",
    "             \"test Open demo of CUT?\"],\n",
    "\n",
    "\"responses\": [ \"A: Definitely. You can try the demo at demo.connectedurbantransport.net. Come back if you have questions. Happy Exploring!\"\n",
    "             ],\n",
    "\"intent\": [\"General_Information\",\"demo\"]\n",
    "},\n",
    "\n",
    "{\n",
    "\"patterns\": [\" What can I do from the traffic management GUI?\", \n",
    "             \" the functionalities of the traffic management GUI\", \n",
    "             \"Give me more information on the GUI?\", \n",
    "             \"What are layer selectors?\", \n",
    "\"Please explain the details of the layer selectors on the GUI\",\n",
    "             \"Where are the layer selectors on the GUI\",\n",
    "\"How do i use the traffic management GUI?\", \n",
    "             \"test Can you share some details on the GUI traffic management?\",\n",
    "             \"how do i use the layer selector?\"],\n",
    "\n",
    "\"responses\": [ \" The main GUI view is divided into three parts: the system map in the center, the layer selector on the right hand side and \\\n",
    "the CTC features on the left hand side. From the system map, you can zoom to different levels. \\\n",
    "The layer selector allows selection of different set of devices,\\\n",
    "such as traffic lights, intersections, etc. The devices are grouped by predefined groups. \\\n",
    "The layer selector group devices into hierarchies. For example, traffic lights and intersections are grouped together under \\\n",
    "Light. Bus, bus stop and bikes are grouped together under public transportation. Clicking on a device icon enables the display\\\n",
    "of that device on the system map. Clicking on a group icon enables display of all devices in the group on the system map.\\\n",
    "CTC allows user to configure its own set of layers.  \"],\n",
    "\n",
    "\"intent\": [\"General_Information\",\"GUI_layer_selector\"]\n",
    "},\n",
    "{\n",
    "\"patterns\": [\"My map is too cluttered. How do I remove some devices from the system map?\", \n",
    "             \"There are too many devices on my map.\", \"Is it possible to remove devices from my map?\", \n",
    "             \"How can I add devices on my map?\", \n",
    "\"How do I make the devices visible on the GUI?\",\n",
    "             \"Tell me how to deselect some Machine 1 on the GUI\",\n",
    "\"How do I remove Ericsson Camera on the GUI?\",\"test Hey bot can you remove Camera X from my map?\", \"test Tell me how to add devices on the GUI?\"],\n",
    "\"responses\": [ \"You can select or de-select any device from the layer selector by clicking on the device icon.\\\n",
    "Alternatively you can select or deselect a group of devices by clicking on the group icon. \"],\n",
    "\"intent\": [\"General_Information\",\"map_removal\"]\n",
    "},\n",
    "    \n",
    "{\n",
    "\"patterns\": [\"hi\", \"how are you\", \"is anyone there\", \"hello\", \"good day\",\n",
    "             \"morning\",\"i would like some help\",\"test Hi there, can some one help me?\"],\n",
    "\"responses\": [ \"Hi there, how can I help?\"],\n",
    "\"intent\": [\"greeting\",\"hello\"]\n",
    "},\n",
    "\n",
    "{\n",
    "\"patterns\": [\"bye\", \"See you later\", \"Goodbye\", \"See you again\",\"thank you for your help\",\"test Good bye\"],\n",
    "\"responses\": [\"See you later, thanks for using HelperBot.\"],\n",
    "\"intent\": [\"greeting\",\"goodbye\"]\n",
    "},\n",
    "\n",
    "{\n",
    "\"patterns\": [\"Hey bot, could you open the search bar\", \"Where is the search function\",\"Show me the search bar\",\"find me the search bar\"\n",
    "             \"The location of search function\",\"how can I access the search bar?\",\"test Open the search bar\",\n",
    "             \"test where can i find the search bar\"],\n",
    "\"responses\": [\"The search bar is at the top on the left side-bar.\"],\n",
    "\"intent\": [\"search_function\",\"search_bar_location\"]\n",
    "},\n",
    "\n",
    "{\n",
    "\"patterns\": [\"search for traffic light 0001-023?\", \"Where is traffic light object?\", \n",
    "             \"Could you search for rail sensor light object?\", \"show me for rail sensor?\",\n",
    "             \"where is location of Gothen Burg Test Interesection on the map?\",\n",
    "             \"locate = Point Machine 001 object?\",\"The location of Ericsson$Camera in the map?\",\n",
    "             \"test Where is the traffic junction 2 on the map?\"],\n",
    "\"responses\": [\"Searching for object <   > right now.\"],\n",
    "\"intent\": [\"search_function\",\"search_for_object\"]\n",
    "},\n",
    "\n",
    "{\n",
    "\"patterns\": [\"search for South Korea?\", \"Where is Haga, Gothenburg?\",\n",
    "             \"Could you search for Nordstan, Nordstadstorget on the map?\", \"Tell me the location of Neosho County?\",\n",
    "             \"Where is location of United States?\",\"Could you locate Nou, Sibiu, Romania?\",\n",
    "             \"The location of Montreal?\",\"test Where is the United States\"],\n",
    "\"responses\": [\"Searching for location <   > right now.\"],\n",
    "\"intent\": [\"search_function\",\"search_for_location\"]\n",
    "},\n",
    "{\n",
    "\"patterns\": [\"Hey bot, Show me all the notifcations?\", \" Where are the notifications?\",\n",
    "             \"Could you open all notifcations?\",\"please turn on the notifcation tab.\",\n",
    "             \"How can I access the notifcations bar?\",\"where is the notification tab?\",\"What notifications are there already?\",\n",
    "             \"What regulations are there\",\n",
    "             \"test Open the notification tab please\"],\n",
    "\"responses\": [\"The notifcations tab is the second tab on the left side bar.\"],\n",
    "\"intent\": [\"notification_function\",\"notification_tab_location\"]\n",
    "},\n",
    "{\n",
    "\"patterns\": [\"Can you sort the notifications by time?\",\"print the latest notifcations\",\n",
    "             \"What are the earliest notifications?\",\"show the most recent notifications\",\n",
    "             \"can i see the most current notifications\",\"test Give me the latest notification\"],\n",
    "\"responses\": [\"Sorting the notifcations by time.\"],\n",
    "\"intent\": [\"notification_function\",\"sort_by_time\"]\n",
    "},\n",
    "\n",
    "{\n",
    "\"patterns\": [\"sort the notifications by importance?\",\n",
    "             \"show the notifications by severity?\",\"tell me the most urgent notifcations.\",\n",
    "             \"How can I find the most urgent notifcations\",\"What notifications are critical?\",\n",
    "             \"print all the major notifications\",\"show all the minor notifications\",\n",
    "             \"test List me the most urgent notifications\"],\n",
    "\"responses\": [\"Sorting the notifcations by importance.\"],\n",
    "\"intent\": [\"notification_function\",\"sort_by_importance\"]\n",
    "},\n",
    "\n",
    "{\n",
    "\"patterns\": [\"sort the notifications by devices?\",\n",
    "             \"give the notifications by machine?\",\"Give me the machines that are notified.\",\n",
    "             \"Which machines give notifications?\",\"What devices needed to be attended to?\",\n",
    "             \"what devices are notified?\",\"test Give me a list of devices on the notifications\"],\n",
    "\"responses\": [\"Sorting the notifcations by device.\"],\n",
    "\"intent\": [\"notification_function\",\"sort_by_device\"]\n",
    "},\n",
    "\n",
    "\n",
    "{\n",
    "\"patterns\": [\"Show me all the alarms?\",\"Give me all the alerts.\",\"Show me all the issues\",\"What are the errors\"\n",
    "             \"Hey bot, Where are the alarms?\",\"Could you open all the alarms?\",\"find me all the alarms\",\n",
    "             \"open the alarms tab.\",\"How can I access the alarms ?\",\"test turn on the alarm tab\",\"test Please log all the errors\"],\n",
    "\"responses\": [\"The alarm tab is the third tab on the left side bar.\"],\n",
    "\"intent\": [\"alarm_function\",\"alarm_tab_location\"]\n",
    "},\n",
    "\n",
    "{\n",
    "\"patterns\": [\"Can you sort the alarms by time?\",\"Give me the latest alarms\",\n",
    "             \"What are the earliest alarms?\",\"show me the most recent alarms?\",\n",
    "             \"Give me the alarms happened today.\",\"test show all alarms happened yesterday?\"],\n",
    "\"responses\": [\"Sorting the alarms by time.\"],\n",
    "\"intent\": [\"alarm_function\",\"sort_by_time\"]\n",
    "},\n",
    "\n",
    "{\n",
    "\"patterns\": [\"Can you sort the alarms by importance?\",\"Give me all the alarms by severity?\",\n",
    "             \"Show all most urgent alarms.\",\"How can I find the most urgent alarms\",\n",
    "             \"What alarms are critical?\",\"list all the major alarms\",\"test List all the critical alrams.\"],\n",
    "\"responses\": [\"Sorting the alarms by importance.\"],\n",
    "\"intent\": [\"alarm_function\",\"sort_by_importance\"]\n",
    "},\n",
    "\n",
    "{\n",
    "\"patterns\": [\"Could you open the Rules tab?\", \"Where are the Rules function?\", \"the location of Rule tab?\", \"What logic can I add? \",\n",
    "             \"What logic can I input? \",\"find me the rules tab\"\n",
    "             \"What are the rules have been created\", \"What are rules\",\"What custom rules are there\",\"show me how to create rules\"\n",
    "             \"test Where is the rule tab?\"],\n",
    "\"responses\": [\"The rules tab is the fourth tab on the left side-bar.\"],\n",
    "\"intent\": [\"rules_function\",\"rules_location\"]\n",
    "},\n",
    "\n",
    "{\n",
    "\"patterns\": [\"How do I create a new rule?\", \"Hey bot, what is the operation for adding a new rule?\",\n",
    "             \"Please add a rule\",\"What policies can i add?\",\"edit a rule for me\",\"create a rule for me\",\n",
    "             \"i want to make a new rule.\",\"I want to create a new rule\",\"test I want to add a new rule\",\n",
    "             \"How do I edit an existing rule?\", \"How do I delete a rule?\", \n",
    "             \"i want to edit send mail by camera upon failure rule\", \"Please edit rule for me\"\n",
    "             \"I want to rewrite the send notification for volume threshold violation rule\",\n",
    "             \"test I want to edit speed up fine rule.\"],\n",
    "\"responses\": [\"Open the rule bar on the left side-bar. click Create Rule button in Blue or find your rule. Click Delete/Edit.\"],\n",
    "\"intent\": [\"rules_function\",\"rules_create_edit_delete\"]\n",
    "},\n",
    "\n",
    "{\n",
    "\"patterns\": [\"change the map style?\", \"Show my map to be like google map?\", \n",
    "             \"Change my map to satellite images on my map\", \"Display street view on map.\",\"Can you open the map for me\"\n",
    "             \"test  change the map too google style.\",\"test Show me the map\",\"Open the map for me\"],\n",
    "\"responses\": [\"Open the map_function on the left side-bar. Then choose the map type you want.\"],\n",
    "\"intent\": [\"map_function\",\"map_edit\"]\n",
    "},\n",
    "\n",
    "{\n",
    "\"patterns\": [\"I want to go to Kibana website?\", \"Where are the links to external websites\", \n",
    "             \"Show me more information on PTV Optima.\",\"How can I get redirected to Kibana?\",\n",
    "             \"Where can I find all the links outside?\",\"test Pease redirect me to Jira\"],\n",
    "\"responses\": [\"Open the Links on the left side-bar. Then choose the External Links you want.\"],\n",
    "\"intent\": [\"links_function\",\"links_display\"]\n",
    "},\n",
    "\n",
    "{\n",
    "\"patterns\": [\"I want to go to my Profile?\", \"How do I check my personal information\", \"What is my age\",\n",
    "             \"How can I change my personal settings?\",\"test Open my personal information page.\"],\n",
    "\"responses\": [\"Open the Profile on the left side-bar.\"],\n",
    "\"intent\": [\"profile_function\",\"profile_sarch\"]\n",
    "},\n",
    "\n",
    "{\n",
    "\"patterns\": [\"I want to Log out?\", \"Please log me out\", \" sign me out\",\"I want to sign out\",\n",
    "             \"Close the application for me.\", \"test sign me out.\"],\n",
    "\"responses\": [\"The sign out button is on the Profile Tab.\"],\n",
    "\"intent\": [\"profile_function\",\"log_out\"]\n",
    "}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from string import punctuation\n",
    "import enchant\n",
    "d = enchant.Dict(\"en_US\")\n",
    "def strip_punctuation(s):\n",
    "    return ''.join(c for c in s if c not in punctuation)\n",
    "\n",
    "def stemmed_sentence(sentence):\n",
    "    out=\"\"\n",
    "    for word in sentence.split(\" \"):\n",
    "        word = strip_punctuation(word)\n",
    "        word= porter_stemmer.stem(word)\n",
    "        out+=word+\" \"\n",
    "    return out\n",
    "        \n",
    "data = []\n",
    "for element_l in L:\n",
    "    for pattern in element_l[\"patterns\"]:\n",
    "        data.append([\"\", stemmed_sentence(pattern),element_l[\"intent\"][0]+\" \"+element_l[\"intent\"][1]])\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Hi there bot what is ctc ', 'General_Information CTC']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22]\n",
      "{'General_Information CTC': 0, 'General_Information CUT': 1, 'General_Information demo': 2, 'General_Information GUI_layer_selector': 3, 'General_Information map_removal': 4, 'greeting hello': 5, 'greeting goodbye': 6, 'search_function search_bar_location': 7, 'search_function search_for_object': 8, 'search_function search_for_location': 9, 'notification_function notification_tab_location': 10, 'notification_function sort_by_time': 11, 'notification_function sort_by_importance': 12, 'notification_function sort_by_device': 13, 'alarm_function alarm_tab_location': 14, 'alarm_function sort_by_time': 15, 'alarm_function sort_by_importance': 16, 'rules_function rules_location': 17, 'rules_function rules_create_edit_delete': 18, 'map_function map_edit': 19, 'links_function links_display': 20, 'profile_function profile_sarch': 21, 'profile_function log_out': 22}\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "labels_index = {}\n",
    "texts = []\n",
    "print(data[0])\n",
    "\n",
    "j = 0\n",
    "for i, item in enumerate(data):\n",
    "    if item[2] not in labels_index:\n",
    "        labels_index[item[2]] = j\n",
    "        j += 1\n",
    "        \n",
    "for item in data:\n",
    "    labels.append(labels_index[item[2]])\n",
    "    texts.append(item[1])\n",
    "print(labels)\n",
    "print(labels_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi there bot what is ctc ', 'tell me more about ctc ', 'pleas explain what is connect traffic cloud ', 'Is there ani inform on ctc ', 'give me some detail about connect traffic cloud ', 'test hey bot what is connect traffic cloud ', 'test tell me about ctc ', 'hey bot what is behind ctc ', 'what technolog power ctc ', 'which team in ericsson is behind connect traffic cloud ', 'what is iot acceler ', 'how is iot platform relat to ctc ', 'how is iot platform relat to  connect traffic cloud ', 'test hey bot what is behind connect urban transport ', 'test how is thi ctc technolog power by ericsson ', 'hey bot what is cut ', 'tell me more about cut ', 'pleas explain what is connect urban transport ', 'I would like to know more about connect urban transport ', 'Is there ani inform on cut ', 'would it be possibl for you to explain to me what is cut ', 'test hey bot what is connect urban transport ', 'test tell me about cut ', 'Ok Im interest to know more can I see a demo ', 'Is there ani demo on cut ', 'open a demo of connect urban transport ', 'would it be possibl for you to show  me what a demo of cut ', 'test hey bot is there ani demo ', 'test open demo of cut ', ' what can I do from the traffic manag gui ', ' the function of the traffic manag gui ', 'give me more inform on the gui ', 'what are layer selector ', 'pleas explain the detail of the layer selector on the gui ', 'where are the layer selector on the gui ', 'how do i use the traffic manag gui ', 'test can you share some detail on the gui traffic manag ', 'how do i use the layer selector ', 'My map is too clutter how do I remov some devic from the system map ', 'there are too mani devic on my map ', 'Is it possibl to remov devic from my map ', 'how can I add devic on my map ', 'how do I make the devic visibl on the gui ', 'tell me how to deselect some machin 1 on the gui ', 'how do I remov ericsson camera on the gui ', 'test hey bot can you remov camera X from my map ', 'test tell me how to add devic on the gui ', 'hi ', 'how are you ', 'is anyon there ', 'hello ', 'good day ', 'morn ', 'i would like some help ', 'test Hi there can some one help me ', 'bye ', 'see you later ', 'goodby ', 'see you again ', 'thank you for your help ', 'test good bye ', 'hey bot could you open the search bar ', 'where is the search function ', 'show me the search bar ', 'find me the search barth locat of search function ', 'how can I access the search bar ', 'test open the search bar ', 'test where can i find the search bar ', 'search for traffic light 0001023 ', 'where is traffic light object ', 'could you search for rail sensor light object ', 'show me for rail sensor ', 'where is locat of gothen burg test interesect on the map ', 'locat  point machin 001 object ', 'the locat of ericssoncamera in the map ', 'test where is the traffic junction 2 on the map ', 'search for south korea ', 'where is haga gothenburg ', 'could you search for nordstan nordstadstorget on the map ', 'tell me the locat of neosho counti ', 'where is locat of unit state ', 'could you locat nou sibiu romania ', 'the locat of montreal ', 'test where is the unit state ', 'hey bot show me all the notifc ', ' where are the notif ', 'could you open all notifc ', 'pleas turn on the notifc tab ', 'how can I access the notifc bar ', 'where is the notif tab ', 'what notif are there alreadi ', 'what regul are there ', 'test open the notif tab pleas ', 'can you sort the notif by time ', 'print the latest notifc ', 'what are the earliest notif ', 'show the most recent notif ', 'can i see the most current notif ', 'test give me the latest notif ', 'sort the notif by import ', 'show the notif by sever ', 'tell me the most urgent notifc ', 'how can I find the most urgent notifc ', 'what notif are critic ', 'print all the major notif ', 'show all the minor notif ', 'test list me the most urgent notif ', 'sort the notif by devic ', 'give the notif by machin ', 'give me the machin that are notifi ', 'which machin give notif ', 'what devic need to be attend to ', 'what devic are notifi ', 'test give me a list of devic on the notif ', 'show me all the alarm ', 'give me all the alert ', 'show me all the issu ', 'what are the errorshey bot where are the alarm ', 'could you open all the alarm ', 'find me all the alarm ', 'open the alarm tab ', 'how can I access the alarm  ', 'test turn on the alarm tab ', 'test pleas log all the error ', 'can you sort the alarm by time ', 'give me the latest alarm ', 'what are the earliest alarm ', 'show me the most recent alarm ', 'give me the alarm happen today ', 'test show all alarm happen yesterday ', 'can you sort the alarm by import ', 'give me all the alarm by sever ', 'show all most urgent alarm ', 'how can I find the most urgent alarm ', 'what alarm are critic ', 'list all the major alarm ', 'test list all the critic alram ', 'could you open the rule tab ', 'where are the rule function ', 'the locat of rule tab ', 'what logic can I add  ', 'what logic can I input  ', 'find me the rule tabwhat are the rule have been creat ', 'what are rule ', 'what custom rule are there ', 'show me how to creat rulestest where is the rule tab ', 'how do I creat a new rule ', 'hey bot what is the oper for ad a new rule ', 'pleas add a rule ', 'what polici can i add ', 'edit a rule for me ', 'creat a rule for me ', 'i want to make a new rule ', 'I want to creat a new rule ', 'test I want to add a new rule ', 'how do I edit an exist rule ', 'how do I delet a rule ', 'i want to edit send mail by camera upon failur rule ', 'pleas edit rule for mei want to rewrit the send notif for volum threshold violat rule ', 'test I want to edit speed up fine rule ', 'chang the map style ', 'show my map to be like googl map ', 'chang my map to satellit imag on my map ', 'display street view on map ', 'can you open the map for metest  chang the map too googl style ', 'test show me the map ', 'open the map for me ', 'I want to go to kibana websit ', 'where are the link to extern websit ', 'show me more inform on ptv optima ', 'how can I get redirect to kibana ', 'where can I find all the link outsid ', 'test peas redirect me to jira ', 'I want to go to my profil ', 'how do I check my person inform ', 'what is my age ', 'how can I chang my person set ', 'test open my person inform page ', 'I want to log out ', 'pleas log me out ', ' sign me out ', 'I want to sign out ', 'close the applic for me ', 'test sign me out ']\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#MAX_NB_WORDS = 117\n",
    "test_index = {}\n",
    "for i in range(0,len(texts)):\n",
    "    if texts[i][:4] ==\"test\":\n",
    "        test_index[i] = True\n",
    "# keras tokenizer, limit number of words to tokenize to MAX_NB_WORDS\n",
    "print(texts)\n",
    "vocab= texts+[additional_texts]\n",
    "tokenizer = Tokenizer(lower=True)\n",
    "tokenizer.fit_on_texts(vocab)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "# the complete word index\n",
    "word_docs = tokenizer.word_docs\n",
    "word_index = tokenizer.word_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for seq in sequences:\n",
    "    if len(seq) > max_len:\n",
    "        max_len = len(seq)\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = max_len\n",
    "\n",
    "\n",
    "print(MAX_SEQUENCE_LENGTH)\n",
    "# stuff in sequences as a list of word indices\n",
    "train_x = []\n",
    "train_y = []\n",
    "test_x = []\n",
    "test_y = []\n",
    "for i in range(0,len(data),1):\n",
    "    if i in test_index:\n",
    "        test_x.append(sequences[i][1:])\n",
    "        test_y.append(labels[i])\n",
    "    else:\n",
    "        train_x.append(sequences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "# restricting length of sequences to MAX_SEQUENCE_LENGTH\n",
    "# takes the last MAX_SEQUENCE_LENGTH words in the list\n",
    "train_x = pad_sequences(train_x, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_x = pad_sequences(test_x, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "# stuff in sequences after processing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 21, 21, 21, 21, 22, 22, 22, 22, 22]\n",
      "[0, 0, 0, 0, 1, 1, 2, 2, 3, 4, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 18, 18, 19, 20, 21, 22]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(train_y)\n",
    "print(test_y)\n",
    "train_y = keras.utils.to_categorical(np.asarray(train_y))\n",
    "test_y = keras.utils.to_categorical(np.asarray(test_y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_x tensor: (153, 16)\n",
      "Shape of train_y tensor: (153, 23)\n",
      "Shape of test_x tensor: (31, 16)\n",
      "Shape of test_y tensor: (31, 23)\n"
     ]
    }
   ],
   "source": [
    "# number of docs X size of sequence\n",
    "print('Shape of train_x tensor:', train_x.shape)\n",
    "\n",
    "# number of docs X size of label vector\n",
    "print('Shape of train_y tensor:', train_y.shape)\n",
    "\n",
    "print('Shape of test_x tensor:', test_x.shape)\n",
    "\n",
    "# number of docs X size of label vector\n",
    "print('Shape of test_y tensor:', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_train = train_x\n",
    "y_train = train_y\n",
    "x_val = test_x\n",
    "y_val = test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tokenizer,open(\"tokenizer.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(274906, 300)\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "\n",
    "# set up a matrix to store the embedding vector for each word in word_index\n",
    "embedding_matrix = np.zeros((len(word_index), EMBEDDING_DIM))\n",
    "print(embedding_matrix.shape)\n",
    "\n",
    "for i, word in enumerate(word_index):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 16)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 16, 300)       82471800    input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)                (None, 16, 128)       38528       embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)                (None, 16, 128)       115328      embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)                (None, 16, 128)       192128      embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)                (None, 16, 128)       384128      embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 16, 512)       0           conv1d_1[0][0]                   \n",
      "                                                                   conv1d_2[0][0]                   \n",
      "                                                                   conv1d_3[0][0]                   \n",
      "                                                                   conv1d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 16, 512)       0           concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling1d_1 (AveragePool (None, 8, 512)        0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 8, 512)        0           average_pooling1d_1[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)                (None, 8, 1024)       1049600     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling1d_2 (AveragePool (None, 4, 1024)       0           conv1d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4, 1024)       0           average_pooling1d_2[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)                (None, 4, 512)        1049088     dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling1d_3 (AveragePool (None, 2, 512)        0           conv1d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1024)          0           average_pooling1d_3[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           131200      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 128)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 64)            8256        dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 64)            0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 23)            1495        dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 85,441,551\n",
      "Trainable params: 85,441,551\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 153 samples, validate on 31 samples\n",
      "Epoch 1/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 3.1428 - acc: 0.0391Epoch 00000: val_acc improved from -inf to 0.12903, saving model to weights-improvement-00-0.13.hdf5\n",
      "153/153 [==============================] - 3s - loss: 3.1425 - acc: 0.0392 - val_loss: 3.1213 - val_acc: 0.1290\n",
      "Epoch 2/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 3.1413 - acc: 0.0547Epoch 00001: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 3.1381 - acc: 0.0523 - val_loss: 3.1210 - val_acc: 0.0645\n",
      "Epoch 3/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 3.1111 - acc: 0.0625Epoch 00002: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 3.1128 - acc: 0.0523 - val_loss: 3.0977 - val_acc: 0.1290\n",
      "Epoch 4/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 3.0887 - acc: 0.0859Epoch 00003: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 3.1044 - acc: 0.0719 - val_loss: 3.0945 - val_acc: 0.1290\n",
      "Epoch 5/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 3.0974 - acc: 0.0547Epoch 00004: val_acc improved from 0.12903 to 0.16129, saving model to weights-improvement-04-0.16.hdf5\n",
      "153/153 [==============================] - 0s - loss: 3.0975 - acc: 0.0523 - val_loss: 3.0859 - val_acc: 0.1613\n",
      "Epoch 6/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 3.0801 - acc: 0.1328Epoch 00005: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 3.0807 - acc: 0.1242 - val_loss: 3.0613 - val_acc: 0.1290\n",
      "Epoch 7/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 3.0788 - acc: 0.1016Epoch 00006: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 3.0761 - acc: 0.0980 - val_loss: 3.0394 - val_acc: 0.1290\n",
      "Epoch 8/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 3.0504 - acc: 0.0703Epoch 00007: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 3.0275 - acc: 0.0915 - val_loss: 3.0130 - val_acc: 0.1613\n",
      "Epoch 9/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.9962 - acc: 0.1406Epoch 00008: val_acc improved from 0.16129 to 0.19355, saving model to weights-improvement-08-0.19.hdf5\n",
      "153/153 [==============================] - 0s - loss: 3.0110 - acc: 0.1176 - val_loss: 3.0199 - val_acc: 0.1935\n",
      "Epoch 10/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.9975 - acc: 0.1094Epoch 00009: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 3.0067 - acc: 0.1111 - val_loss: 2.9898 - val_acc: 0.1935\n",
      "Epoch 11/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.9775 - acc: 0.1094Epoch 00010: val_acc improved from 0.19355 to 0.25806, saving model to weights-improvement-10-0.26.hdf5\n",
      "153/153 [==============================] - 0s - loss: 2.9743 - acc: 0.1176 - val_loss: 2.9697 - val_acc: 0.2581\n",
      "Epoch 12/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.9807 - acc: 0.1172Epoch 00011: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - 0s - loss: 2.9712 - acc: 0.1176 - val_loss: 2.9391 - val_acc: 0.2258\n",
      "Epoch 13/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.9299 - acc: 0.1328Epoch 00012: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 2.9231 - acc: 0.1438 - val_loss: 2.9064 - val_acc: 0.1935\n",
      "Epoch 14/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.8941 - acc: 0.1641Epoch 00013: val_acc improved from 0.25806 to 0.29032, saving model to weights-improvement-13-0.29.hdf5\n",
      "153/153 [==============================] - 0s - loss: 2.8943 - acc: 0.1569 - val_loss: 2.9337 - val_acc: 0.2903\n",
      "Epoch 15/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.8575 - acc: 0.1953Epoch 00014: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 2.8489 - acc: 0.2026 - val_loss: 2.8781 - val_acc: 0.2903\n",
      "Epoch 16/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.8014 - acc: 0.2109Epoch 00015: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 2.8168 - acc: 0.2092 - val_loss: 2.8505 - val_acc: 0.2903\n",
      "Epoch 17/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.7888 - acc: 0.2188Epoch 00016: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 2.7857 - acc: 0.2222 - val_loss: 2.8090 - val_acc: 0.2258\n",
      "Epoch 18/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.7558 - acc: 0.2109Epoch 00017: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 2.7668 - acc: 0.2026 - val_loss: 2.8152 - val_acc: 0.2903\n",
      "Epoch 19/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.6805 - acc: 0.2266Epoch 00018: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 2.6891 - acc: 0.2157 - val_loss: 2.7378 - val_acc: 0.2903\n",
      "Epoch 20/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.7072 - acc: 0.2266Epoch 00019: val_acc improved from 0.29032 to 0.32258, saving model to weights-improvement-19-0.32.hdf5\n",
      "153/153 [==============================] - 0s - loss: 2.6846 - acc: 0.2222 - val_loss: 2.7097 - val_acc: 0.3226\n",
      "Epoch 21/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.6899 - acc: 0.2500Epoch 00020: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 2.6644 - acc: 0.2549 - val_loss: 2.6831 - val_acc: 0.3226\n",
      "Epoch 22/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.5559 - acc: 0.2500Epoch 00021: val_acc improved from 0.32258 to 0.38710, saving model to weights-improvement-21-0.39.hdf5\n",
      "153/153 [==============================] - 0s - loss: 2.5688 - acc: 0.2353 - val_loss: 2.6600 - val_acc: 0.3871\n",
      "Epoch 23/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.5499 - acc: 0.2578Epoch 00022: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 2.5634 - acc: 0.2549 - val_loss: 2.6686 - val_acc: 0.2903\n",
      "Epoch 24/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.4773 - acc: 0.2891Epoch 00023: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 2.5286 - acc: 0.2745 - val_loss: 2.6023 - val_acc: 0.3548\n",
      "Epoch 25/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.4745 - acc: 0.2891Epoch 00024: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 2.4383 - acc: 0.3072 - val_loss: 2.5758 - val_acc: 0.3226\n",
      "Epoch 26/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.4513 - acc: 0.3203Epoch 00025: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 2.4517 - acc: 0.3072 - val_loss: 2.5221 - val_acc: 0.3871\n",
      "Epoch 27/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.4277 - acc: 0.3047Epoch 00026: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 2.4447 - acc: 0.2876 - val_loss: 2.5376 - val_acc: 0.2903\n",
      "Epoch 28/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.3568 - acc: 0.3281Epoch 00027: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 2.3719 - acc: 0.3203 - val_loss: 2.4418 - val_acc: 0.3548\n",
      "Epoch 29/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.2635 - acc: 0.3516Epoch 00028: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 2.2687 - acc: 0.3660 - val_loss: 2.4315 - val_acc: 0.3226\n",
      "Epoch 30/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.2818 - acc: 0.3203Epoch 00029: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 2.3117 - acc: 0.3203 - val_loss: 2.4036 - val_acc: 0.3548\n",
      "Epoch 31/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.1522 - acc: 0.3906Epoch 00030: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 2.1659 - acc: 0.3725 - val_loss: 2.3352 - val_acc: 0.3548\n",
      "Epoch 32/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.2344 - acc: 0.3125Epoch 00031: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 2.2237 - acc: 0.3203 - val_loss: 2.3354 - val_acc: 0.3871\n",
      "Epoch 33/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.1651 - acc: 0.4297Epoch 00032: val_acc improved from 0.38710 to 0.45161, saving model to weights-improvement-32-0.45.hdf5\n",
      "153/153 [==============================] - 0s - loss: 2.1772 - acc: 0.3856 - val_loss: 2.3389 - val_acc: 0.4516\n",
      "Epoch 34/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.1183 - acc: 0.4062Epoch 00033: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 2.1593 - acc: 0.3856 - val_loss: 2.2685 - val_acc: 0.4516\n",
      "Epoch 35/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.9943 - acc: 0.4219Epoch 00034: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 2.0283 - acc: 0.3922 - val_loss: 2.2687 - val_acc: 0.3871\n",
      "Epoch 36/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 2.0455 - acc: 0.3906Epoch 00035: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 2.0566 - acc: 0.4118 - val_loss: 2.2482 - val_acc: 0.4516\n",
      "Epoch 37/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.9872 - acc: 0.4688Epoch 00036: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.9848 - acc: 0.4641 - val_loss: 2.1678 - val_acc: 0.4194\n",
      "Epoch 38/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.9617 - acc: 0.3906Epoch 00037: val_acc improved from 0.45161 to 0.48387, saving model to weights-improvement-37-0.48.hdf5\n",
      "153/153 [==============================] - 0s - loss: 2.0240 - acc: 0.3595 - val_loss: 2.1862 - val_acc: 0.4839\n",
      "Epoch 39/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.8961 - acc: 0.4531Epoch 00038: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.8952 - acc: 0.4706 - val_loss: 2.1174 - val_acc: 0.4839\n",
      "Epoch 40/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.9043 - acc: 0.4531Epoch 00039: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.8587 - acc: 0.4706 - val_loss: 2.1175 - val_acc: 0.3871\n",
      "Epoch 41/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.8400 - acc: 0.4375Epoch 00040: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.7832 - acc: 0.4641 - val_loss: 2.1129 - val_acc: 0.4194\n",
      "Epoch 42/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.8480 - acc: 0.4766Epoch 00041: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.8700 - acc: 0.4771 - val_loss: 2.0546 - val_acc: 0.4194\n",
      "Epoch 43/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.8104 - acc: 0.4609Epoch 00042: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.8025 - acc: 0.4641 - val_loss: 2.0065 - val_acc: 0.4516\n",
      "Epoch 44/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.7632 - acc: 0.5156Epoch 00043: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - 0s - loss: 1.7488 - acc: 0.5163 - val_loss: 1.9854 - val_acc: 0.4516\n",
      "Epoch 45/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.7304 - acc: 0.5234Epoch 00044: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.6699 - acc: 0.5359 - val_loss: 2.0158 - val_acc: 0.4839\n",
      "Epoch 46/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.6264 - acc: 0.5391Epoch 00045: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.6225 - acc: 0.5359 - val_loss: 1.8921 - val_acc: 0.3871\n",
      "Epoch 47/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.5385 - acc: 0.6094Epoch 00046: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.5669 - acc: 0.5817 - val_loss: 1.8875 - val_acc: 0.4194\n",
      "Epoch 48/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.5958 - acc: 0.5156Epoch 00047: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.5988 - acc: 0.5229 - val_loss: 1.8672 - val_acc: 0.4516\n",
      "Epoch 49/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.5220 - acc: 0.5938Epoch 00048: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.5214 - acc: 0.5817 - val_loss: 1.8928 - val_acc: 0.4194\n",
      "Epoch 50/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.4952 - acc: 0.5859Epoch 00049: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.5034 - acc: 0.5752 - val_loss: 1.7943 - val_acc: 0.4839\n",
      "Epoch 51/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.4558 - acc: 0.5781Epoch 00050: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.4436 - acc: 0.5817 - val_loss: 1.7780 - val_acc: 0.4839\n",
      "Epoch 52/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.4203 - acc: 0.6094Epoch 00051: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.4348 - acc: 0.5948 - val_loss: 1.7247 - val_acc: 0.4839\n",
      "Epoch 53/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.3349 - acc: 0.6562Epoch 00052: val_acc improved from 0.48387 to 0.54839, saving model to weights-improvement-52-0.55.hdf5\n",
      "153/153 [==============================] - 0s - loss: 1.4094 - acc: 0.6209 - val_loss: 1.6738 - val_acc: 0.5484\n",
      "Epoch 54/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.3887 - acc: 0.6250Epoch 00053: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.3987 - acc: 0.6209 - val_loss: 1.7134 - val_acc: 0.5161\n",
      "Epoch 55/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.2802 - acc: 0.6328Epoch 00054: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.2583 - acc: 0.6536 - val_loss: 1.6568 - val_acc: 0.4839\n",
      "Epoch 56/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.3056 - acc: 0.6016Epoch 00055: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.2932 - acc: 0.6275 - val_loss: 1.6723 - val_acc: 0.5161\n",
      "Epoch 57/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.2458 - acc: 0.6641Epoch 00056: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.2637 - acc: 0.6601 - val_loss: 1.6178 - val_acc: 0.5161\n",
      "Epoch 58/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.1752 - acc: 0.6875Epoch 00057: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.1515 - acc: 0.6993 - val_loss: 1.6685 - val_acc: 0.4516\n",
      "Epoch 59/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.1960 - acc: 0.7188Epoch 00058: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.2764 - acc: 0.6732 - val_loss: 1.6396 - val_acc: 0.5161\n",
      "Epoch 60/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.1238 - acc: 0.7344Epoch 00059: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.1176 - acc: 0.7255 - val_loss: 1.6363 - val_acc: 0.4839\n",
      "Epoch 61/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.0599 - acc: 0.7422Epoch 00060: val_acc improved from 0.54839 to 0.61290, saving model to weights-improvement-60-0.61.hdf5\n",
      "153/153 [==============================] - 0s - loss: 1.0632 - acc: 0.7190 - val_loss: 1.6235 - val_acc: 0.6129\n",
      "Epoch 62/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.1386 - acc: 0.6562Epoch 00061: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.1038 - acc: 0.6863 - val_loss: 1.4935 - val_acc: 0.6129\n",
      "Epoch 63/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.0121 - acc: 0.7266Epoch 00062: val_acc improved from 0.61290 to 0.64516, saving model to weights-improvement-62-0.65.hdf5\n",
      "153/153 [==============================] - 0s - loss: 1.0697 - acc: 0.7124 - val_loss: 1.4514 - val_acc: 0.6452\n",
      "Epoch 64/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.0623 - acc: 0.6953Epoch 00063: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.0422 - acc: 0.7059 - val_loss: 1.4847 - val_acc: 0.6452\n",
      "Epoch 65/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.9266 - acc: 0.7812Epoch 00064: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.9433 - acc: 0.7712 - val_loss: 1.4378 - val_acc: 0.5806\n",
      "Epoch 66/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 1.1612 - acc: 0.6641Epoch 00065: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 1.0891 - acc: 0.7059 - val_loss: 1.4125 - val_acc: 0.6452\n",
      "Epoch 67/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.9799 - acc: 0.7266Epoch 00066: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.9638 - acc: 0.7320 - val_loss: 1.4278 - val_acc: 0.6129\n",
      "Epoch 68/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.9667 - acc: 0.6953Epoch 00067: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.8995 - acc: 0.7320 - val_loss: 1.4278 - val_acc: 0.6129\n",
      "Epoch 69/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.8841 - acc: 0.7422Epoch 00068: val_acc improved from 0.64516 to 0.70968, saving model to weights-improvement-68-0.71.hdf5\n",
      "153/153 [==============================] - 1s - loss: 0.8854 - acc: 0.7516 - val_loss: 1.3325 - val_acc: 0.7097\n",
      "Epoch 70/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.9428 - acc: 0.7656Epoch 00069: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.9439 - acc: 0.7778 - val_loss: 1.3468 - val_acc: 0.6452\n",
      "Epoch 71/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.8617 - acc: 0.8047Epoch 00070: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.8580 - acc: 0.7974 - val_loss: 1.2552 - val_acc: 0.6774\n",
      "Epoch 72/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.7419 - acc: 0.8125Epoch 00071: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.7595 - acc: 0.8039 - val_loss: 1.1919 - val_acc: 0.6774\n",
      "Epoch 73/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.7797 - acc: 0.7344Epoch 00072: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.7487 - acc: 0.7582 - val_loss: 1.3256 - val_acc: 0.6452\n",
      "Epoch 74/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.7056 - acc: 0.8438Epoch 00073: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.7104 - acc: 0.8431 - val_loss: 1.1932 - val_acc: 0.6774\n",
      "Epoch 75/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.7162 - acc: 0.7969Epoch 00074: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.7295 - acc: 0.7843 - val_loss: 1.2509 - val_acc: 0.6774\n",
      "Epoch 76/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.7089 - acc: 0.8203Epoch 00075: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.7401 - acc: 0.8039 - val_loss: 1.2229 - val_acc: 0.6129\n",
      "Epoch 77/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/153 [========================>.....] - ETA: 0s - loss: 0.8014 - acc: 0.7578Epoch 00076: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.7382 - acc: 0.7908 - val_loss: 1.1595 - val_acc: 0.6452\n",
      "Epoch 78/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.6440 - acc: 0.8438Epoch 00077: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.7006 - acc: 0.8170 - val_loss: 1.1798 - val_acc: 0.6774\n",
      "Epoch 79/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.6771 - acc: 0.8281Epoch 00078: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.6235 - acc: 0.8431 - val_loss: 1.1590 - val_acc: 0.6774\n",
      "Epoch 80/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.6525 - acc: 0.8594Epoch 00079: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.6493 - acc: 0.8562 - val_loss: 1.1999 - val_acc: 0.6774\n",
      "Epoch 81/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.6648 - acc: 0.8359Epoch 00080: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.6358 - acc: 0.8431 - val_loss: 1.1381 - val_acc: 0.6774\n",
      "Epoch 82/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.5817 - acc: 0.8125Epoch 00081: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.6030 - acc: 0.8170 - val_loss: 1.1404 - val_acc: 0.6774\n",
      "Epoch 83/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.6492 - acc: 0.8203Epoch 00082: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.6439 - acc: 0.8235 - val_loss: 1.0939 - val_acc: 0.6452\n",
      "Epoch 84/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.5774 - acc: 0.8438Epoch 00083: val_acc improved from 0.70968 to 0.74194, saving model to weights-improvement-83-0.74.hdf5\n",
      "153/153 [==============================] - 2s - loss: 0.5455 - acc: 0.8497 - val_loss: 1.1326 - val_acc: 0.7419\n",
      "Epoch 85/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.6752 - acc: 0.8203Epoch 00084: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.6593 - acc: 0.8235 - val_loss: 1.0385 - val_acc: 0.7419\n",
      "Epoch 86/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.5347 - acc: 0.8828Epoch 00085: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.5498 - acc: 0.8758 - val_loss: 1.0571 - val_acc: 0.7097\n",
      "Epoch 87/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.5327 - acc: 0.8672Epoch 00086: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.5060 - acc: 0.8693 - val_loss: 1.0377 - val_acc: 0.6774\n",
      "Epoch 88/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.5183 - acc: 0.8828Epoch 00087: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.5343 - acc: 0.8758 - val_loss: 1.0235 - val_acc: 0.6774\n",
      "Epoch 89/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.4519 - acc: 0.8750Epoch 00088: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.4361 - acc: 0.8824 - val_loss: 1.0282 - val_acc: 0.6774\n",
      "Epoch 90/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.3452 - acc: 0.9453Epoch 00089: val_acc improved from 0.74194 to 0.77419, saving model to weights-improvement-89-0.77.hdf5\n",
      "153/153 [==============================] - 4s - loss: 0.3700 - acc: 0.9412 - val_loss: 0.9397 - val_acc: 0.7742\n",
      "Epoch 91/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.4384 - acc: 0.9062Epoch 00090: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.4284 - acc: 0.9085 - val_loss: 0.9838 - val_acc: 0.7097\n",
      "Epoch 92/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.4687 - acc: 0.8438Epoch 00091: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.4860 - acc: 0.8497 - val_loss: 0.9503 - val_acc: 0.7419\n",
      "Epoch 93/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.3945 - acc: 0.9141Epoch 00092: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.3812 - acc: 0.9216 - val_loss: 1.0384 - val_acc: 0.6774\n",
      "Epoch 94/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.4812 - acc: 0.8672Epoch 00093: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.4510 - acc: 0.8824 - val_loss: 0.9195 - val_acc: 0.7097\n",
      "Epoch 95/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.4302 - acc: 0.8438Epoch 00094: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.4192 - acc: 0.8627 - val_loss: 0.8833 - val_acc: 0.7742\n",
      "Epoch 96/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.4307 - acc: 0.8750Epoch 00095: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.4571 - acc: 0.8627 - val_loss: 0.9611 - val_acc: 0.6774\n",
      "Epoch 97/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.2964 - acc: 0.9375Epoch 00096: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.3205 - acc: 0.9281 - val_loss: 0.9001 - val_acc: 0.7419\n",
      "Epoch 98/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.3269 - acc: 0.8828Epoch 00097: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.3456 - acc: 0.8824 - val_loss: 0.8638 - val_acc: 0.7419\n",
      "Epoch 99/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.2902 - acc: 0.9297Epoch 00098: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.2913 - acc: 0.9281 - val_loss: 0.9440 - val_acc: 0.7097\n",
      "Epoch 100/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.2536 - acc: 0.9453Epoch 00099: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.2720 - acc: 0.9281 - val_loss: 0.9316 - val_acc: 0.7742\n",
      "Epoch 101/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.3558 - acc: 0.8984Epoch 00100: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.3799 - acc: 0.8889 - val_loss: 1.0251 - val_acc: 0.6129\n",
      "Epoch 102/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.3936 - acc: 0.8672Epoch 00101: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.3766 - acc: 0.8758 - val_loss: 0.9448 - val_acc: 0.7097\n",
      "Epoch 103/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.2827 - acc: 0.9531Epoch 00102: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.3038 - acc: 0.9542 - val_loss: 0.9165 - val_acc: 0.7742\n",
      "Epoch 104/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.2918 - acc: 0.9219Epoch 00103: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.2691 - acc: 0.9346 - val_loss: 0.9741 - val_acc: 0.6774\n",
      "Epoch 105/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.3239 - acc: 0.9375Epoch 00104: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.2967 - acc: 0.9477 - val_loss: 0.8378 - val_acc: 0.7097\n",
      "Epoch 106/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.2302 - acc: 0.9609Epoch 00105: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.2323 - acc: 0.9542 - val_loss: 0.8089 - val_acc: 0.7742\n",
      "Epoch 107/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.3342 - acc: 0.8750Epoch 00106: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.3251 - acc: 0.8954 - val_loss: 0.7934 - val_acc: 0.7419\n",
      "Epoch 108/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1710 - acc: 0.9609Epoch 00107: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.2120 - acc: 0.9477 - val_loss: 0.8465 - val_acc: 0.7742\n",
      "Epoch 109/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.2383 - acc: 0.9531Epoch 00108: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.2408 - acc: 0.9542 - val_loss: 0.9134 - val_acc: 0.7097\n",
      "Epoch 110/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/153 [========================>.....] - ETA: 0s - loss: 0.2668 - acc: 0.9375Epoch 00109: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.2867 - acc: 0.9150 - val_loss: 0.8801 - val_acc: 0.7097\n",
      "Epoch 111/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.2168 - acc: 0.9531Epoch 00110: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.2456 - acc: 0.9346 - val_loss: 0.7705 - val_acc: 0.7419\n",
      "Epoch 112/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.2687 - acc: 0.9375Epoch 00111: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.2609 - acc: 0.9412 - val_loss: 0.8658 - val_acc: 0.7097\n",
      "Epoch 113/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.2311 - acc: 0.9531Epoch 00112: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.2306 - acc: 0.9477 - val_loss: 0.8379 - val_acc: 0.7419\n",
      "Epoch 114/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1976 - acc: 0.9688Epoch 00113: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.2226 - acc: 0.9608 - val_loss: 0.8718 - val_acc: 0.7419\n",
      "Epoch 115/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.2638 - acc: 0.9219Epoch 00114: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.2396 - acc: 0.9346 - val_loss: 0.8456 - val_acc: 0.7419\n",
      "Epoch 116/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1970 - acc: 0.9531Epoch 00115: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.2234 - acc: 0.9477 - val_loss: 0.8185 - val_acc: 0.7097\n",
      "Epoch 117/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1842 - acc: 0.9531Epoch 00116: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.2031 - acc: 0.9412 - val_loss: 0.9242 - val_acc: 0.7097\n",
      "Epoch 118/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1519 - acc: 0.9688Epoch 00117: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1771 - acc: 0.9608 - val_loss: 0.7981 - val_acc: 0.7419\n",
      "Epoch 119/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1508 - acc: 0.9922Epoch 00118: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1775 - acc: 0.9804 - val_loss: 0.9060 - val_acc: 0.7097\n",
      "Epoch 120/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.2538 - acc: 0.9219Epoch 00119: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.2434 - acc: 0.9216 - val_loss: 0.7766 - val_acc: 0.7742\n",
      "Epoch 121/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.2351 - acc: 0.9375Epoch 00120: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.2195 - acc: 0.9412 - val_loss: 0.8064 - val_acc: 0.7419\n",
      "Epoch 122/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1531 - acc: 0.9844Epoch 00121: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1609 - acc: 0.9804 - val_loss: 0.8653 - val_acc: 0.7419\n",
      "Epoch 123/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1505 - acc: 0.9609Epoch 00122: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1459 - acc: 0.9608 - val_loss: 0.8043 - val_acc: 0.7097\n",
      "Epoch 124/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1492 - acc: 0.9688Epoch 00123: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1459 - acc: 0.9673 - val_loss: 0.8902 - val_acc: 0.7742\n",
      "Epoch 125/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1522 - acc: 0.9688Epoch 00124: val_acc improved from 0.77419 to 0.80645, saving model to weights-improvement-124-0.81.hdf5\n",
      "153/153 [==============================] - 5s - loss: 0.1474 - acc: 0.9673 - val_loss: 0.7739 - val_acc: 0.8065\n",
      "Epoch 126/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1279 - acc: 0.9766Epoch 00125: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1279 - acc: 0.9804 - val_loss: 0.8277 - val_acc: 0.7419\n",
      "Epoch 127/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1672 - acc: 0.9609Epoch 00126: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1621 - acc: 0.9608 - val_loss: 0.7809 - val_acc: 0.8065\n",
      "Epoch 128/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1559 - acc: 0.9453Epoch 00127: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1589 - acc: 0.9477 - val_loss: 0.8472 - val_acc: 0.8065\n",
      "Epoch 129/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1522 - acc: 0.9844Epoch 00128: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1588 - acc: 0.9739 - val_loss: 0.8385 - val_acc: 0.7742\n",
      "Epoch 130/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1212 - acc: 0.9844Epoch 00129: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1213 - acc: 0.9869 - val_loss: 0.8438 - val_acc: 0.8065\n",
      "Epoch 131/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1265 - acc: 0.9531Epoch 00130: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1161 - acc: 0.9608 - val_loss: 0.9078 - val_acc: 0.7419\n",
      "Epoch 132/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1523 - acc: 0.9531Epoch 00131: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1547 - acc: 0.9542 - val_loss: 0.8994 - val_acc: 0.7742\n",
      "Epoch 133/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1285 - acc: 0.9766Epoch 00132: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1399 - acc: 0.9739 - val_loss: 0.9130 - val_acc: 0.7742\n",
      "Epoch 134/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1339 - acc: 0.9609Epoch 00133: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1229 - acc: 0.9673 - val_loss: 0.7408 - val_acc: 0.7742\n",
      "Epoch 135/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1377 - acc: 0.9609Epoch 00134: val_acc improved from 0.80645 to 0.83871, saving model to weights-improvement-134-0.84.hdf5\n",
      "153/153 [==============================] - 14s - loss: 0.1361 - acc: 0.9608 - val_loss: 0.8510 - val_acc: 0.8387\n",
      "Epoch 136/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1679 - acc: 0.9609Epoch 00135: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1611 - acc: 0.9608 - val_loss: 0.7639 - val_acc: 0.8065\n",
      "Epoch 137/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1032 - acc: 0.9844Epoch 00136: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1044 - acc: 0.9804 - val_loss: 0.8529 - val_acc: 0.8387\n",
      "Epoch 138/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1002 - acc: 0.9609Epoch 00137: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0927 - acc: 0.9673 - val_loss: 0.8668 - val_acc: 0.7097\n",
      "Epoch 139/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0876 - acc: 0.9844Epoch 00138: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0869 - acc: 0.9869 - val_loss: 0.7036 - val_acc: 0.8065\n",
      "Epoch 140/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1128 - acc: 0.9688Epoch 00139: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1082 - acc: 0.9739 - val_loss: 0.7581 - val_acc: 0.7742\n",
      "Epoch 141/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0574 - acc: 0.9922Epoch 00140: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0690 - acc: 0.9869 - val_loss: 0.8899 - val_acc: 0.7419\n",
      "Epoch 142/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1301 - acc: 0.9609Epoch 00141: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1169 - acc: 0.9673 - val_loss: 0.8625 - val_acc: 0.7742\n",
      "Epoch 143/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1158 - acc: 0.9688Epoch 00142: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1120 - acc: 0.9739 - val_loss: 0.7615 - val_acc: 0.8387\n",
      "Epoch 144/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1247 - acc: 0.9453Epoch 00143: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1186 - acc: 0.9477 - val_loss: 0.8414 - val_acc: 0.8065\n",
      "Epoch 145/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0731 - acc: 0.9844Epoch 00144: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0789 - acc: 0.9804 - val_loss: 0.7887 - val_acc: 0.7742\n",
      "Epoch 146/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1343 - acc: 0.9609Epoch 00145: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1175 - acc: 0.9673 - val_loss: 0.8303 - val_acc: 0.7742\n",
      "Epoch 147/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0938 - acc: 0.9766Epoch 00146: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0835 - acc: 0.9804 - val_loss: 0.8304 - val_acc: 0.7742\n",
      "Epoch 148/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1143 - acc: 0.9844Epoch 00147: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1277 - acc: 0.9739 - val_loss: 0.7615 - val_acc: 0.7419\n",
      "Epoch 149/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0839 - acc: 0.9922Epoch 00148: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0973 - acc: 0.9869 - val_loss: 0.7238 - val_acc: 0.7419\n",
      "Epoch 150/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1181 - acc: 0.9766Epoch 00149: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1060 - acc: 0.9804 - val_loss: 0.7988 - val_acc: 0.8387\n",
      "Epoch 151/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0753 - acc: 0.9922Epoch 00150: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0722 - acc: 0.9935 - val_loss: 0.7551 - val_acc: 0.8387\n",
      "Epoch 152/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1082 - acc: 0.9609Epoch 00151: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1001 - acc: 0.9673 - val_loss: 0.7697 - val_acc: 0.7419\n",
      "Epoch 153/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0785 - acc: 0.9766Epoch 00152: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0720 - acc: 0.9804 - val_loss: 0.8643 - val_acc: 0.7419\n",
      "Epoch 154/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0671 - acc: 0.9844Epoch 00153: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0773 - acc: 0.9804 - val_loss: 0.7746 - val_acc: 0.7742\n",
      "Epoch 155/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1056 - acc: 0.9766Epoch 00154: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0946 - acc: 0.9804 - val_loss: 0.8794 - val_acc: 0.7097\n",
      "Epoch 156/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0668 - acc: 0.9844Epoch 00155: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0588 - acc: 0.9869 - val_loss: 0.8221 - val_acc: 0.8065\n",
      "Epoch 157/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0539 - acc: 0.9844Epoch 00156: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0559 - acc: 0.9869 - val_loss: 0.7647 - val_acc: 0.8387\n",
      "Epoch 158/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0598 - acc: 0.9844Epoch 00157: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0540 - acc: 0.9869 - val_loss: 0.7608 - val_acc: 0.7742\n",
      "Epoch 159/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.1362 - acc: 0.9688Epoch 00158: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1237 - acc: 0.9739 - val_loss: 0.7529 - val_acc: 0.8065\n",
      "Epoch 160/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0490 - acc: 0.9844Epoch 00159: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0497 - acc: 0.9869 - val_loss: 0.8169 - val_acc: 0.7419\n",
      "Epoch 161/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0407 - acc: 0.9922Epoch 00160: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0371 - acc: 0.9935 - val_loss: 0.7333 - val_acc: 0.8065\n",
      "Epoch 162/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0625 - acc: 0.9844Epoch 00161: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0779 - acc: 0.9804 - val_loss: 0.7094 - val_acc: 0.8387\n",
      "Epoch 163/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0933 - acc: 0.9766Epoch 00162: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.1011 - acc: 0.9739 - val_loss: 0.8583 - val_acc: 0.7742\n",
      "Epoch 164/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0662 - acc: 0.9766Epoch 00163: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0653 - acc: 0.9739 - val_loss: 0.8299 - val_acc: 0.7742\n",
      "Epoch 165/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0588 - acc: 0.9844Epoch 00164: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0551 - acc: 0.9869 - val_loss: 0.9101 - val_acc: 0.7097\n",
      "Epoch 166/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0436 - acc: 1.0000Epoch 00165: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0444 - acc: 1.0000 - val_loss: 1.1480 - val_acc: 0.6452\n",
      "Epoch 167/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0519 - acc: 0.9922Epoch 00166: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0586 - acc: 0.9869 - val_loss: 0.8808 - val_acc: 0.8065\n",
      "Epoch 168/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0926 - acc: 0.9766Epoch 00167: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0946 - acc: 0.9739 - val_loss: 0.8789 - val_acc: 0.8065\n",
      "Epoch 169/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0326 - acc: 1.0000Epoch 00168: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0585 - acc: 0.9804 - val_loss: 0.8993 - val_acc: 0.8065\n",
      "Epoch 170/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0469 - acc: 0.9844Epoch 00169: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0662 - acc: 0.9673 - val_loss: 0.7803 - val_acc: 0.7742\n",
      "Epoch 171/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0733 - acc: 0.9766Epoch 00170: val_acc improved from 0.83871 to 0.87097, saving model to weights-improvement-170-0.87.hdf5\n",
      "153/153 [==============================] - 10s - loss: 0.0734 - acc: 0.9739 - val_loss: 0.7145 - val_acc: 0.8710\n",
      "Epoch 172/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0212 - acc: 1.0000Epoch 00171: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0319 - acc: 0.9935 - val_loss: 0.9068 - val_acc: 0.8065\n",
      "Epoch 173/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0812 - acc: 0.9766Epoch 00172: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0714 - acc: 0.9804 - val_loss: 0.7228 - val_acc: 0.8387\n",
      "Epoch 174/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0846 - acc: 0.9844Epoch 00173: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0761 - acc: 0.9869 - val_loss: 0.7390 - val_acc: 0.7742\n",
      "Epoch 175/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0285 - acc: 0.9922Epoch 00174: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0258 - acc: 0.9935 - val_loss: 0.8026 - val_acc: 0.8065\n",
      "Epoch 176/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0452 - acc: 0.9922Epoch 00175: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0388 - acc: 0.9935 - val_loss: 0.8039 - val_acc: 0.7742\n",
      "Epoch 177/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0669 - acc: 0.9922Epoch 00176: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0590 - acc: 0.9935 - val_loss: 0.9129 - val_acc: 0.7419\n",
      "Epoch 178/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0933 - acc: 0.9688Epoch 00177: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0794 - acc: 0.9739 - val_loss: 0.9856 - val_acc: 0.7742\n",
      "Epoch 179/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0515 - acc: 0.9922Epoch 00178: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0454 - acc: 0.9935 - val_loss: 0.8245 - val_acc: 0.8065\n",
      "Epoch 180/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0612 - acc: 0.9844Epoch 00179: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0593 - acc: 0.9869 - val_loss: 0.9412 - val_acc: 0.8065\n",
      "Epoch 181/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0424 - acc: 0.9922Epoch 00180: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0384 - acc: 0.9935 - val_loss: 0.8740 - val_acc: 0.7742\n",
      "Epoch 182/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0445 - acc: 0.9844Epoch 00181: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0477 - acc: 0.9869 - val_loss: 0.8874 - val_acc: 0.8387\n",
      "Epoch 183/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0414 - acc: 1.0000Epoch 00182: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0445 - acc: 0.9935 - val_loss: 0.8370 - val_acc: 0.7742\n",
      "Epoch 184/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0234 - acc: 0.9922Epoch 00183: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0219 - acc: 0.9935 - val_loss: 0.9208 - val_acc: 0.7742\n",
      "Epoch 185/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0333 - acc: 0.9922Epoch 00184: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0347 - acc: 0.9935 - val_loss: 0.9539 - val_acc: 0.7097\n",
      "Epoch 186/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0446 - acc: 0.9922Epoch 00185: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0458 - acc: 0.9869 - val_loss: 0.8193 - val_acc: 0.7742\n",
      "Epoch 187/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0505 - acc: 0.9922Epoch 00186: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0492 - acc: 0.9869 - val_loss: 1.1092 - val_acc: 0.7419\n",
      "Epoch 188/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0295 - acc: 1.0000Epoch 00187: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0325 - acc: 0.9935 - val_loss: 1.0774 - val_acc: 0.7419\n",
      "Epoch 189/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0284 - acc: 0.9922Epoch 00188: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0263 - acc: 0.9935 - val_loss: 0.6926 - val_acc: 0.7742\n",
      "Epoch 190/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0486 - acc: 0.9844Epoch 00189: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0422 - acc: 0.9869 - val_loss: 0.7430 - val_acc: 0.8065\n",
      "Epoch 191/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0266 - acc: 0.9922Epoch 00190: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0288 - acc: 0.9935 - val_loss: 0.8515 - val_acc: 0.7419\n",
      "Epoch 192/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0610 - acc: 0.9922Epoch 00191: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0714 - acc: 0.9869 - val_loss: 0.9379 - val_acc: 0.7419\n",
      "Epoch 193/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0170 - acc: 1.0000Epoch 00192: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0193 - acc: 1.0000 - val_loss: 1.0016 - val_acc: 0.8065\n",
      "Epoch 194/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0447 - acc: 0.9766Epoch 00193: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0412 - acc: 0.9804 - val_loss: 0.8166 - val_acc: 0.8387\n",
      "Epoch 195/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0282 - acc: 1.0000Epoch 00194: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0400 - acc: 0.9935 - val_loss: 0.8337 - val_acc: 0.8065\n",
      "Epoch 196/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0427 - acc: 0.9922Epoch 00195: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0462 - acc: 0.9935 - val_loss: 0.8516 - val_acc: 0.7419\n",
      "Epoch 197/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0358 - acc: 0.9922Epoch 00196: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0324 - acc: 0.9935 - val_loss: 0.8538 - val_acc: 0.8065\n",
      "Epoch 198/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0339 - acc: 0.9922Epoch 00197: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0330 - acc: 0.9935 - val_loss: 0.8308 - val_acc: 0.7742\n",
      "Epoch 199/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0140 - acc: 1.0000Epoch 00198: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0147 - acc: 1.0000 - val_loss: 0.8884 - val_acc: 0.7419\n",
      "Epoch 200/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0107 - acc: 1.0000Epoch 00199: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0098 - acc: 1.0000 - val_loss: 1.0467 - val_acc: 0.7097\n",
      "Epoch 201/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0460 - acc: 0.9844Epoch 00200: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0409 - acc: 0.9869 - val_loss: 0.7880 - val_acc: 0.8065\n",
      "Epoch 202/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0576 - acc: 0.9609Epoch 00201: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0522 - acc: 0.9673 - val_loss: 0.7530 - val_acc: 0.7742\n",
      "Epoch 203/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0349 - acc: 0.9922Epoch 00202: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0500 - acc: 0.9869 - val_loss: 0.9645 - val_acc: 0.8065\n",
      "Epoch 204/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0167 - acc: 0.9922Epoch 00203: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0155 - acc: 0.9935 - val_loss: 0.6669 - val_acc: 0.8710\n",
      "Epoch 205/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0116 - acc: 1.0000Epoch 00204: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0120 - acc: 1.0000 - val_loss: 0.7580 - val_acc: 0.8065\n",
      "Epoch 206/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0257 - acc: 0.9922Epoch 00205: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0219 - acc: 0.9935 - val_loss: 0.8497 - val_acc: 0.8387\n",
      "Epoch 207/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0507 - acc: 0.9844Epoch 00206: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0503 - acc: 0.9869 - val_loss: 1.0455 - val_acc: 0.7097\n",
      "Epoch 208/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0183 - acc: 0.9922Epoch 00207: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0192 - acc: 0.9935 - val_loss: 0.8491 - val_acc: 0.8387\n",
      "Epoch 209/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0450 - acc: 0.9922Epoch 00208: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - 0s - loss: 0.0405 - acc: 0.9935 - val_loss: 1.1237 - val_acc: 0.7097\n",
      "Epoch 210/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0395 - acc: 0.9922Epoch 00209: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0337 - acc: 0.9935 - val_loss: 0.8528 - val_acc: 0.8387\n",
      "Epoch 211/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0160 - acc: 0.9922Epoch 00210: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0206 - acc: 0.9869 - val_loss: 0.9543 - val_acc: 0.8065\n",
      "Epoch 212/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0380 - acc: 0.9922Epoch 00211: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0468 - acc: 0.9869 - val_loss: 1.2779 - val_acc: 0.7419\n",
      "Epoch 213/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0226 - acc: 0.9922Epoch 00212: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0197 - acc: 0.9935 - val_loss: 0.9490 - val_acc: 0.8065\n",
      "Epoch 214/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0606 - acc: 0.9922Epoch 00213: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0515 - acc: 0.9935 - val_loss: 0.9640 - val_acc: 0.8065\n",
      "Epoch 215/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0381 - acc: 0.9844Epoch 00214: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0460 - acc: 0.9869 - val_loss: 1.0291 - val_acc: 0.7742\n",
      "Epoch 216/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0141 - acc: 1.0000Epoch 00215: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0402 - acc: 0.9869 - val_loss: 0.8109 - val_acc: 0.8710\n",
      "Epoch 217/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0127 - acc: 1.0000Epoch 00216: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0178 - acc: 0.9935 - val_loss: 0.8829 - val_acc: 0.8065\n",
      "Epoch 218/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0236 - acc: 1.0000Epoch 00217: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0217 - acc: 1.0000 - val_loss: 1.1271 - val_acc: 0.7419\n",
      "Epoch 219/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0503 - acc: 0.9844Epoch 00218: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0520 - acc: 0.9869 - val_loss: 0.9731 - val_acc: 0.8065\n",
      "Epoch 220/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0280 - acc: 0.9922Epoch 00219: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0250 - acc: 0.9935 - val_loss: 0.9108 - val_acc: 0.8065\n",
      "Epoch 221/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0364 - acc: 0.9922Epoch 00220: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0497 - acc: 0.9804 - val_loss: 1.0056 - val_acc: 0.8387\n",
      "Epoch 222/10000\n",
      "128/153 [========================>.....] - ETA: 0s - loss: 0.0333 - acc: 0.9844Epoch 00221: val_acc did not improve\n",
      "153/153 [==============================] - 0s - loss: 0.0287 - acc: 0.9869 - val_loss: 0.9290 - val_acc: 0.7742\n",
      "Epoch 223/10000\n",
      " 96/153 [=================>............] - ETA: 0s - loss: 0.0472 - acc: 0.9792"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7778b6818e45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m model.fit(x_train, y_train, validation_data=(x_val, y_val),\n\u001b[0;32m---> 55\u001b[0;31m           epochs=10000, verbose=1,callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[0;32m/home/elamuon/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1593\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/home/elamuon/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1180\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/elamuon/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2268\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2269\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2270\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2271\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/elamuon/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/elamuon/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/elamuon/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/elamuon/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/elamuon/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Input, Dense, Conv1D, MaxPooling1D, Flatten, AveragePooling1D\n",
    "from keras.layers.pooling import GlobalMaxPooling1D\n",
    "from keras.layers.core import Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, add, Activation, concatenate, Flatten\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "embedding_layer = Embedding(len(word_index),\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x0 = Conv1D(128, 1, activation='relu',padding=\"same\", strides=1)(embedded_sequences)\n",
    "x1 = Conv1D(128, 3, activation='relu',padding=\"same\", strides=1)(embedded_sequences)\n",
    "x2 = Conv1D(128, 5, activation='relu',padding=\"same\", strides=1)(embedded_sequences)\n",
    "x3 = Conv1D(128, 10, activation='relu',padding=\"same\", strides=1)(embedded_sequences)\n",
    "\n",
    "x = concatenate([x0, x1, x2 ,x3],  axis=-1)\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "x = AveragePooling1D(2)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Conv1D(1024, 2, activation='relu',padding=\"same\", strides=1)(x)\n",
    "x = AveragePooling1D(2)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Conv1D(512, 2, activation='relu',padding=\"same\", strides=1)(x)\n",
    "x = AveragePooling1D(2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "preds = Dense(len(labels_index), activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.summary()\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.RMSprop(lr=0.0001, rho=0.4, epsilon=1e-08, decay=0.0),\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          epochs=10000, verbose=1,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tokenizer,open(\"tokenizer.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(274906, 300)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
